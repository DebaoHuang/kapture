= kapture / datasets
:sectnums:
:sectnumlevels: 1
:toc:
:toclevels: 1

This section explains how to convert datasets to kapture format.

== 7-scenes

TODO: A word about the choices we made.

=== convert from original dataset

=== download precomputed kapture data

== Aachen-Day-Night-v1.1

We imported all mapping and query images as well as the provided reference poses from the original dataset. Note that v1.1 is based on the original version. More information about that can be found on the dataset owners' webpage.

=== convert from original dataset

Aachen-Day-Night-v1.1 is available here: https://data.ciirc.cvut.cz/public/projects/2020VisualLocalization/Aachen-Day-Night/

1) Download the following data from the original source:

- images/database_and_query_images.zip
- aachen_v1_1.zip
- queries/day_time_queries_with_intrinsics.txt

2) Prepare data

- Extract the two archives.
- Create a folder named 'aachenv11' and prepare (move/copy the just downloaded data) the following folder structure:

[source,txt]
----
aachenv11
|-- images
|   |-- db                                      (from images/database_and_query_images.zip)
|   |-- sequences                               (from aachen_v1_1.zip)
|   |   |-- gopro3_undistorted
|   |   |-- nexus4_sequences
|   |   |   |-- sequence_1
|   |   |   |-- ...
|   |   |   |-- sequence_8
|   |-- query
|   |   |-- day                                 (from images/database_and_query_images.zip)
|   |   |   |-- milestone
|   |   |   |-- nexus4
|   |   |   |-- nexus5x
|   |   |-- night
|   |   |   |-- milestone                       (from images/database_and_query_images.zip)
|   |   |   |-- nexus5x                         (from images/database_and_query_images.zip)
|   |   |   |-- nexus5x_additional_night        (from aachen_v1_1.zip)
|-- day_time_queries_with_intrinsics.txt
|-- night_time_queries_with_intrinsics.txt      (from aachen_v1_1.zip)
|-- 3D-models                                   (from aachen_v1_1.zip)
|   |-- aachen_v1_1
|-- kapture
----

3) Create the kaptures for the query images

Call this from aachenv11:

[source,bash]
----
# note: on windows, this requires admin rights for symlinks
# see https://docs.python.org/3.6/library/os.html#os.symlink
kapture_import_image_list.py -v debug -i day_time_queries_with_intrinsics.txt -o kapture/query_day -im images
kapture_import_image_list.py -v debug -i night_time_queries_with_intrinsics.txt -o kapture/query_night -im images

# if you can't use symlinks, add this to the two commands: --image_transfer copy
----

Now you have separate kaptures for day-time and night-time queries. If you would like to have one single kapture, run from aachenv11:
[source,bash]
----
kapture_merge.py -v debug -i kapture/query_day kapture/query_night -o kapture/query
----

4) Create the kapture for the mapping images

- Convert the COLMAP reconstructions from .bin to .txt. Call this from aachenv11:
[source,bash]
----
colmap model_converter --input_path 3D-models/aachen_v_1_1 --output_path 3D-models/aachen_v_1_1 --output_type TXT
----

- Convert COLMAP model to kapture. Call this from aachenv11:
[source,bash]
----
# note: on windows, this requires admin rights for symlinks
# see https://docs.python.org/3.6/library/os.html#os.symlink
kapture_import_colmap.py -v debug -txt 3D-models/aachen_v_1_1/ -im images -o kapture/mapping --skip_reconstruction

# if you can't use symlinks, add this to the command: --image_transfer copy
----


=== download precomputed kapture data

wip

== baidu

TODO: A word about the choices we made.

=== convert from original dataset

=== download precomputed kapture data

== Cambridge_Landmarks

TODO: A word about the choices we made.

=== convert from original dataset

== Extended-CMU-Seasons

We imported the poses from the text files. The same sliced structure is replicated.
In the precomputed kapture data, we decided to import all images, even if they are not listed in the text files (they do not have a pose).
In kapture_import_Extended_CMU_Seasons.py, it corresponds to the option --all-files.

=== convert from original dataset

Extended-CMU-Seasons is available here: https://data.ciirc.cvut.cz/public/projects/2020VisualLocalization/Extended-CMU-Seasons/

Once downloaded, and all tar files extracted, your Extended-CMU-Seasons directory is like this:

[source,txt]
----
Extended-CMU-Seasons
├─ README_Extended-CMU-Seasons.md
├─ export_sift_features.py
├─ intrinsics.txt
├─ slice2/
│  ├─ camera-poses/
│  │  ├─ slice-2-gt-query-images-20100901.txt
│  │  ├─ ...
│  ├─ database/
│  │  ├─ img_00119_c0_1303398474779439us.jpg
│  │  ├─ ...
│  ├─ database2.db
│  ├─ ground-truth-database-images-slice2.txt
│  ├─ query/
│  │  ├─ img_00273_c1_1287503834101037us.jpg
│  │  ├─ ...
│  ├─ query2.db
│  ├─ sparse/
│  │  ├─ cameras.bin
│  │  ├─ images.bin
│  │  └─ points3D.bin
│  └─ test-images-slice2.txt
├─ slice3/
├─ slice4/
├─ ...
└─ slice25/
----

To import Extended-CMU-Seasons to kapture, run:
[source,bash]
----
# note: on windows, this requires admin rights for symlinks
# see https://docs.python.org/3.6/library/os.html#os.symlink
kapture_import_Extended_CMU_Seasons.py -v info -i ./Extended-CMU-Seasons/ -o ./kapture/Extended-CMU-Seasons/ --image_transfer link_absolute --all-files

# if you can't use symlinks, run
kapture_import_Extended_CMU_Seasons.py -v info -i ./Extended-CMU-Seasons/ -o ./kapture/Extended-CMU-Seasons/ --image_transfer copy --all-files
----

=== download precomputed kapture data

== InLoc

For the conversion to kapture, we used the provided (cutout) images as well as the camera poses. In detail, the kapture data consists of all cutout images from DUC1 and DUC2 as well as all query images. For now, we do not provide the other buildings (only DUC1 and DUC2 are used for the online benchmark).

InLoc also provides 3D scans for each cutout image. These 3D files can be found in the same folder like the RGB images.

e.g.: image name: DUC_cutout_000_120_30.jpg
-> corresponding 3D file name: DUC_cutout_000_120_30.jpg.mat

=== download precomputed kapture data

The original dataset description page can be found here: http://www.ok.sc.e.titech.ac.jp/INLOC/

1) Download the precomputed kapture data from here: TODO url

2a) Download the original database images (cutouts) and scans from here: http://www.ok.sc.e.titech.ac.jp/INLOC/materials/cutouts.tar.gz

2b) Or download only the images (no scans) from here: http://www.ok.sc.e.titech.ac.jp/INLOC/materials/cutouts_imageonly.tar.bz2

3) Download the query images from here: http://www.ok.sc.e.titech.ac.jp/INLOC/materials/iphone7.tar.gz

4) Link, copy or move the database and query image folders (which also contain the scans if you downloaded them) to the previously downloaded kaptures (from step 1). Your InLoc folder should look like this:

[source,txt]
----
InLoc
|-- DUC1_alignment (contains some txt files)
|-- DUC2_alignment (contains some txt files)
|-- mapping
|   |-- sensors
|   |   |-- records_camera.txt
|   |   |-- sensors.txt
|   |   |-- trajectories.txt
|   |   |-- records_data
|   |   |   |-- DUC1                (from cutouts.tar.gz or cutouts_imageonly.tar.bz2)
|   |   |   |-- DUC2                (from cutouts.tar.gz or cutouts_imageonly.tar.bz2)
|-- query
|   |-- sensors
|   |   |-- records_camera.txt
|   |   |-- sensors.txt
|   |   |-- records_data
|   |   |   |-- iphone7             (from iphone7.tar.gz)
----

5) If you would like to use the Inloc 3D scan data, please read the readme_kapture.txt file we provided with the dataset (from step 1).

== RobotCar_Seasons-v2

Each folder (from 01/ to 49/) contains a kapture dataset for the mapping data (mapping/), and some folders also contain one for the queries (query/). They are self-contained (include all data and images related to this location)
Intrinsics are read from the text files, not the reconstructions.
For the new training images of v2, we only included the poses for the original data (poses for rear camera only). It is possible to get the poses for the other 2 cameras by leveraging the known rig configuration with the function
[source,python]
----
# in https://github.com/naver/kapture/blob/master/kapture/core/Trajectories.py
kapture.rigs_recover_inplace(kdata_mapping.trajectories, kdata_mapping.rigs, 'rear') 
----

=== convert from original dataset
 RobotCar_Seasons is available here: https://data.ciirc.cvut.cz/public/projects/2020VisualLocalization/RobotCar-Seasons/
 To import it into kapture, you'll need these files:
[source,txt]
----
RobotCar-Seasons
├─ 3D-models/
│  └─ individual/
│     ├─ colmap_reconstructions/
│     │  ├─ 001_aligned/
│     │  │  ├─ cameras.txt
│     │  │  ├─ images.txt
│     │  │  └─ points3D.txt
│     │  ├─ 002_aligned/
│     │  ├─ ...
│     │  └─ 049_aligned/
│     └─ queries_per_location/
│        ├─ queries_location_001.txt
│        ├─ queries_location_002.txt
│        ├─ ...
│        └─ queries_location_049.txt
├─ LICENSE.txt
├─ README_RobotCar-Seasons.md
├─ README_RobotCar_v2.md
├─ extrinsics/
│  ├─ left_extrinsics.txt
│  ├─ rear_extrinsics.txt
│  └─ right_extrinsics.txt
├─ images/
├─ intrinsics/
│  ├─ left_intrinsics.txt
│  ├─ intrinsics.txt
│  └─ intrinsics.txt
├─ robotcar_v2_test.txt
└─ robotcar_v2_train.txt
----

To import RobotCar-Seasons-v2 to kapture, run:
[source,bash]
----
# note: on windows, this requires admin rights for symlinks
# see https://docs.python.org/3.6/library/os.html#os.symlink
kapture_import_RobotCar_Seasons.py -v debug -i ./RobotCar-Seasons -o ./kapture/RobotCar-Seasons-v2 --skip_reconstruction

# if you can't use symlinks, add this to the command: --image_transfer copy
# if you want to import v1 instead (deprecated), add this to the command: --v1
----

=== download precomputed kapture data

== SILDa

For the conversion to kapture, we used the provided images as well as the camera poses.

.fisheye cameras
Cameras used for SILDA are fisheye cameras, with a wide field of view.
The creator of the dataset defines their own camera model suited for fisheye and
the associated parameters. Nevertheless, we are not able to convert this custom camera model
into kapture. Consequently, we choose to use standard camera model (FOV) fitting
the SILDA's fisheyes. We also provides the re-estimated parameters for the FOV model.

.Rig
The SILDA camera is a 2-lens rig, and is converted ensuring timestamps of both
camera are identical for images taken simultaneously. A theoretical rig configuration
is also provided in rigs.txt. But the rig constraint is not used is the pose estimation.


=== convert from original dataset

1) download the original dataset

The authors provide a bash script `download.sh` to download all the available data for SILDa.
See the https://github.com/abmmusa/silda for more details.

[source,bash]
----
cd /your/working/dataset/directory  # replace the path
curl -L https://github.com/abmmusa/silda/raw/master/download.sh -o download.sh
chmod +x download.sh
./download.sh  # <  total of around 60GB data will be downloaded
----

or you can download only data relevant to kapture, applying the following command in bash terminal:

[source,bash]
----
mkdir -p ./data/SILDa
# Downloading full spherical images
wget -O im1 -L https://imperialcollegelondon.box.com/shared/static/ce2kkt0j4uir9tpzcxx55lhfr05bbjx9
wget -O im2 -L https://imperialcollegelondon.box.com/shared/static/j4rx03ymwajz98wsfgbocrurwjq4l68h
cat im* > silda-images.tgz
tar xvzf silda-images.tgz
mv silda-images ./data/SILDa/
rm im1 im2 silda-images.tgz

# Downloading camera intrinsics
wget -O camera-intrinsics.tar.xz -L https://imperialcollegelondon.box.com/shared/static/pug92l2sw2n375eqrqo92j63p5qm5dqo.xz
tar xvf camera-intrinsics.tar.xz
mv camera-intrinsics ./data/SILDa/
rm camera-intrinsics.tar.xz

# Download camera poses for the train images
wget -O silda-train-poses.txt -L https://imperialcollegelondon.box.com/shared/static/jr67j3uw8sz97j4vw8la3j3vbhzfwpnz.txt
mv silda-train-poses.txt ./data/SILDa/

# Download train and test images split
wget -O train_imgs.txt -L https://imperialcollegelondon.box.com/shared/static/m71jx5h09heygzttn85v96z6ouz03dbv.txt
wget -O query_imgs.txt -L https://imperialcollegelondon.box.com/shared/static/hfa2l5lw86asskjv6efp8lvoipc8elc8.txt
mv train_imgs.txt query_imgs.txt ./data/SILDa/
----

You should have:

----
./data/SILDa/
├── camera-intrinsics/
├── query_imgs.txt
├── silda-images/
├── silda-train-poses.txt
└── train_imgs.txt
----

2) import into kapture format

[source,bash]
----
# mapping query
kapture_import_silda.py -v info --image_transfer copy -i ./data/SILDa -o ./kapture/mapping --corpus mapping
kapture_import_silda.py -v info --image_transfer copy -i ./data/SILDa -o ./kapture/query --corpus query
# uncomment the following, if you want the both mapping and query in the same dataset
# kapture_import_silda.py -v info --image_transfer copy -i ./data/SILDa -o ./kapture/mapping_query
# then [optionally] clean original
rm -rf ./data/SILDa
----

You should end up with:

----
./kapture
├── mapping
│   └── sensors
│       ├── records_camera.txt
│       ├── records_data/
│       ├── rigs.txt
│       ├── sensors.txt
│       └── trajectories.txt
└── query
    └── sensors
        ├── records_camera.txt
        ├── records_data/
        ├── rigs.txt
        ├── sensors.txt
        └── trajectories.txt
----

With additional options, you can:

- `--cam_model`, choose the camera model (`FOV` or `OPENCV_FISHEYE`)
- `--split_cams` tells the importer to reorganise image files using `<cam_id>/<timestamp:04d>.jpg` template,
- `--rig_collapse` replaces camera poses with rig poses.
